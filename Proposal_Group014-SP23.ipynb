{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COGS 118A- Project Proposal"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Description\n",
    "\n",
    "You will design and execute a machine learning project. There are a few constraints on the nature of the allowed project. \n",
    "- The problem addressed will not be a \"toy problem\" or \"common training students problem\" like mtcars, iris, palmer penguins etc.\n",
    "- The dataset will have >1k observations and >5 variables. I'd prefer more like >10k observations and >10 variables. A general rule is that if you have >100x more observations than variables, your solution will likely generalize a lot better. The goal of training a supervised machine learning model is to learn the underlying pattern in a dataset in order to generalize well to unseen data, so choosing a large dataset is very important.\n",
    "\n",
    "- The project will include a model selection and/or feature selection component where you will be looking for the best setup to maximize the performance of your ML system.\n",
    "- You will evaluate the performance of your ML system using more than one appropriate metric\n",
    "- You will be writing a report describing and discussing these accomplishments\n",
    "\n",
    "\n",
    "Feel free to delete this description section when you hand in your proposal."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Peer Review\n",
    "\n",
    "You will all have an opportunity to look at the Project Proposals of other groups to fuel your creativity and get more ideas for how you can improve your own projects. \n",
    "\n",
    "Both the project proposal and project checkpoint will have peer review."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Names\n",
    "\n",
    "- Yilin Zhu\n",
    "- Gavin Roberts"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Abstract \n",
    "\n",
    "In this project, we want to predict customer churn for a telecom company using the Telco Customer Churn dataset from IBM company. \n",
    "The data contains information about a telco company that provided home phone and Internet services to 7043 customers in California in Q3. It indicates which customers have left, stayed, or signed up for their service. Multiple important demographics are included for each customer, as well as a Satisfaction Score, Churn Score, and Customer Lifetime Value (CLTV) index.I will use machine learning algorithms to analyze the data and predict customer churn. One goal is identifying which factors are most strongly associated with churn. I will use various models and algorithms, including logistic regression, decision trees, and random forests to compare their performance. And I will use techniques such as cross validation to select the best model. The success will be measured using metrics such as accuracy, precision, recall, and F1 score: they will give me a comprehensive understanding of the model's performance. The ultimate goal is helping the telecom company to better understand their customers and take proactive steps to reduce churn rates and improve customer retention."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Background\n",
    "\n",
    "Customer churn prediction is a crucial problem in the field of business analytics. It has been studied extensively by practitioners from various field in the business world<a name=\"name1\"></a>[<sup>[1]</sup>](#name1n). The motive for studying this sort of problem is to predict whether a customer is likely to leave a company's service so that the companies could come up with proactive schemes to retain their customers and maintain the stability of revenue flows. One hypothesis is that the tenure would be one of the deciding factors: longer then tenure, less likely the customer churn would happen. This is because intuitively people were less likely to make a change when they used the service from the company for a long time. Intuitively, their consumption habits may not change drastically.\\\n",
    "To begin with, we have a Telco Customer Churn dataset from IBM Business Analytics<a name=\"name2\"></a>[<sup>[2]</sup>](#name2n), and it has been used by practitioners to develop and test machine learning models. The dataset consists important customer information such as tenure, total charges, subscriptions, and contract type. The final prediction variable is customer churn.\\\n",
    "The approaches include employing Machine learning algorithms such as logistic regression, random forests, decision trees, support vector machine and neural networks could be used to predict customer churn. Previous studies have shown that the models combining multiple algorithms perform better than individual models<a name=\"name3\"></a>[<sup>[3]</sup>](#name3n). For this project, I would use different algorithms seperately and compare the performance of these algorithms as well as the model selections.\\\n",
    "The performance of the machine learning models would be evaluated using metrics such as accuracy, precision, recall, and F1 score. Cross-validation and hyperparameter tuning techniques are widely used to optimize the model's performance<a name=\"name4\"></a>[<sup>[4]</sup>](#name4n)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem Statement\n",
    "\n",
    "In this problem, I need to predict customer churn for a telecommunication company with supervised machine learning methods. Here is a definition of Customer Churn: it is a phenomenon that customers stop doing business with a company and switch to that company's competitor. In the context of a teleco company, churn can be caused by various factors such as increased price, poor customer service, and better offers from competitors. The problem is quantifiable because the ultimate goal is predicting whether a customer will churn or not (binary classification) based on features such as their tenure, contract type, payment method, etc. Such problem could be further expressed with classification algorithms. I could measure the performance of the algorithms and models with a rainbow of metrics such as precision, recall, F1 score, and AUC-ROC curve. The problem is replicable since it can be reproduced using the same dataset and features to train and test various supervised machine learning models to predict customer churn for other similar companies or for a same company with data in the future."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data\n",
    "\n",
    "Link: https://community.ibm.com/community/user/businessanalytics/blogs/steven-macko/2019/07/11/telco-customer-churn-1113\n",
    "\n",
    "In this project, I am using the Telco Customer Churn dataset from IBM Business Analytics. This dataset consists of customer information for a telecommunications company, including their tenure, satisfaction score, churn score, and customer lifetime value. Other importan variables involves customer demographics (such as gender and age), account information (such as contract type and payment method), and usage patterns (such as monthly charges and total charges).This dataset contains 7043 observations and 21 variables, with each observation representing a unique customer with a unique id. \n",
    "\n",
    "One crucial variable in this dataset is the \"Churn\" variable: it indicates whether or not a customer has declined the company's service. This variable will be used as the target variable in our machine learning models, and it would be used for testing accuracy. Another important variable is \"Tenure,\" which represents the length of time a customer has been with the company. This variable would have a significant impact on a customer's likelihood of churning for the reason that customers who have been with the company for a longer period of time may be more likely to stay.\n",
    "\n",
    "Cleaning and preprocessing will be required for preparing the data analysis. One important task is to use one-hot encoding to transform categorical variables into numerical variables. Also, unecessary variables such as user IDs should be removed. Certain normalizations are needed to scale the importance of different variables into a same level."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proposed Solution\n",
    "\n",
    "An ideal solution is implementing different binary classification algorithms such as logistic regression, support vector machines, and random forest. Since the goal is to predict whether a customer will churn or not based on the level of importance for different variables, I may want to conduct PCA to perform dimension reduction. Generally, this problem could be solved with supervised machine learning methods: we need to split the data into training, testing, and validation sections. Specifically, I train the model based on the provided \"churn\" label: customers who have churned and those who have not. Cross validation should be performed as the size of the dataset is not very big.\n",
    "\n",
    "- **Exploratory Data Analysis (EDA):** \\\n",
    "    I need to summarize the main characteristics of a dataset by visualizing the variables. This enables me to gain more insight about the data. The goal of EDA is to understand the distribution of the data and detect any outliers. Fortunately, some variables could be removed directly by observing the distributions when I identify patterns among variables.\n",
    "\n",
    "- **Preprocess Data:** \\\n",
    "    Data Cleaning. Perform one-hot encoding.\n",
    "\n",
    "- **Dimension Reduction & Feature Selection:**\\ \n",
    "    Since there are 21 variables, it potentially includes a lot of noise. So I may want to remove the features with little impact in decision making. Ideally, Principal Component Analysis should be performed. I may want to use XGBoost. Or I could use the result from EDA and remove some features based on reasoning.\n",
    "\n",
    "- **Algorithms:** \\\n",
    "    Since customer churn is a classification problem, we could use the following algorithms.\n",
    "    * **Support Vector Machine**\\\n",
    "        SVM is a good fit for classification and regression tasks. It will try to find the hyperplane that best separates (maximizes the margin) the data into different classes. In the context of customer churn, aregular SVM would work fine. We can use it to predict whether a customer is likely to churn or not based on various features like their tenure, demographics, usage patterns, etc. It is also a great algorithm for data that need to draw nonlinear decision boundaries. We could use the kernel trick to map the original features to a higher dimensional space.\n",
    "    * **K Nearest Neighbors**\\\n",
    "        KNN is a non-parametric algorithm that could be used in classification tasks. The output is based on the k-nearest data points in the training set. The training process is basically storing the data. The testing could consume more time as it needs to calculate the distance pairwise. In the context of customer churn, we can use KNN to predict whether a customer is likely to churn based on the similar customers in the training set.\n",
    "    * **Logistic Classification**\\\n",
    "         It is a statistical algorithm used for classifications. The underlying mechanics is maximum likelihood optimization. In the context of customer churn, we can use logistic regression to predict whether a customer is likely to churn or not.\n",
    "    * **Decision Tree**\\\n",
    "        It is a non-parametric algorithm. Specifically, the algorithm creates a tree-like model of decisions and their possible consequences. Mathematically, it tries different threshold to maximize the information gain. Meaning that at each spliting stage, it finds the feature that best seperate customer from churn and stay. \n",
    "\n",
    "- **Model Selection:** \\\n",
    "    Use  k-fold cross-validation to ensure the model's performance is reliable and robust.Try different algorithms and tune the hyperparameter to enhance the result. Hyperparameters such as regularization strength or number of trees in the random forest could be changed using grid search or randomized search to improve model performance.\n",
    "\n",
    "- **Algorithm evaluation:** \\\n",
    "    Employ nested cross validation. Use different metrics for evaluation. See below."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation Metrics\n",
    "\n",
    "For the model and algorithm evaluation metrics, we will use recall, sensitivity, F1-score, accuracy, and AUC-ROC. \n",
    "\n",
    "- $\\textbf{Recall} = \\frac{\\text{TP}}{\\text{TP + FN}}$\n",
    "\n",
    "    It is the proportion of actual positives that are correctly identified by the model. In our context, it is the probability of successful identification of customer churns given that customer churns happen. Essentially, we want to maximize this metric to have a more accurate model.\n",
    "    \n",
    "\n",
    "- $\\textbf{Precision} = \\frac{\\text{TP}}{\\text{TP+FP}}$\n",
    "\n",
    "    It is the fraction of actual positives given among all positive predictions made by the model. In our project, it helps us see the performance of our model because it measure the probability of correct predictions given that the model makes a positive prediction. Namely, it refers to the proportion of customers who are predicted to churn and actually do churn, out of all the customers who are predicted to churn.\n",
    " \n",
    " \n",
    "- $\\textbf{Accuracy} = \\frac{\\text{TP+TN}}{\\text{TP+TN+FP+FN}}$\n",
    "\n",
    "    This would evaluate the fraction of correct predictions among all predictions.\n",
    "    \n",
    "    \n",
    "- $\\textbf{F1-score} = \\frac{\\text{2 * Precision * Recall}}{\\text{Precision + Recall}}$\n",
    "\n",
    "    When comparing 2 models, it is likely that model A has a higher precision and model B has a higher recall. When this happen, we want to pick a model that have a relatively balanced value between precision and recall. We could compare the F1-scores because it represents the harmonic mean of precision and recall.\n",
    "    \n",
    "    \n",
    "- $\\textbf{Receiver Operating Characteristic (AUC-ROC)}$\n",
    "\n",
    "    ROC is generated by plotting the true positive rate against the false positive rate at various thresholds.\\\n",
    "    In this context, the threshold is a value between 0 and 1. For example, when a logistic model output 0.75 as a probability that a customer churn may happen, the final decision really depends on the threshold value: if we set the threshold to be 0.8, then it would still be classified as negative even with a high value.\\\n",
    "    Ideally, we want to pick a threshold that make the TPR to be 1 for any FPR.\\\n",
    "    The AUC is the area under the ROC curve. A good classifier would have an AUC of 1: it rank all positive samples higher than negative samples for any threshold value. This is what we want because we want the model to have a strong ability to identify actual customer churns. We won't care too much about the negatives (customers stay) as it is not a loss for the company."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ethics & Privacy"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the customer churn project, the privacy of the customers should be a top concern. Specifically, the dataset contains variables that may reveal customers' consuming habits in telecon services, and we want to protect the customers' privacy by eliminating the information that help identify individuals. Besides this, the customers should be notified that their data is used for the prediction. And fortuantely, the customers appearing in our dataset are anonymous, meaning that their privacy is protected. The id numbers in the dataset does not reveal any personal information, and thus it will not do harm to customers' privacy.When the models are trained and put into daily practice by the company, certain issues should be considered deliberately. For example, all the customers should be noted that their data would be used, and the customers should have the right to opt out anytime.  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Team Expectations "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Speak in group chat. Respond to messages.\n",
    "* Manage deadlines effectively.\n",
    "* Encourage active listening.\n",
    "* Contribute to the project somehow.\n",
    "* Look at the repo and do some work."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Timeline Proposal"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|  Date  | Need to Complete  | Assignment |\n",
    "|---|---|---|\n",
    "| 5/14  | Pick Proposal      | Determine proposal and project | \n",
    "| 5/15  | Work on the proposal |                       | \n",
    "| 5/16  | Finish Proposal     |    |\n",
    "| 5/17  | Finalize Proposal    | Data Cleaning and EDA   |\n",
    "| 5/20  | Finalize wrangling/EDA; Begin programming for project | |\n",
    "| 5/23  |                   |  |\n",
    "| 5/30  | NA | NA  |"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Footnotes\n",
    "\n",
    "<a name=\"name1n\"></a>1.[^](#name1): K. Dahiya and S. Bhatia. Customer churn analysis in telecom industry. 2015 4th International Conference on Reliability.Infocom Technologies and Optimization (ICRITO.https://ieeexplore.ieee.org/abstract/document/7359318 <br>\n",
    "<a name=\"name2n\"></a>2.[^](#name2): Telco Customer Churn dataset. IBM Business Analytics. https://community.ibm.com/community/user/businessanalytics/blogs/steven-macko/2019/07/11/telco-customer-churn-1113 <br>\n",
    "<a name=\"name3n\"></a>3.[^](#name3):Suh, Y. Machine learning based customer churn prediction in home appliance rental business. J Big Data 10, 41 (2023). https://doi.org/10.1186/s40537-023-00721-8 <br>\n",
    "<a name=\"name4n\"></a>4.[^](#name4): Bhuse, P., Gandhi, A., Meswani, P., Muni, R., & Katre, N. (2020). Machine Learning Based Telecom-Customer Churn Prediction. 2020 3rd International Conference on Intelligent Sustainable Systems (ICISS), 1297-1301.https://www.semanticscholar.org/paper/Machine-Learning-Based-Telecom-Customer-Churn-Bhuse-Gandhi/daf8cc73ed7fb8f474cbfa111db0118edee4b5ee <br>\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
